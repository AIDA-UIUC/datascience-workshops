{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZk84yjV4Le-"
   },
   "source": [
    "# **SIG AIDA Data Science Workshop**\n",
    "## _Punching Through Data with Pandas_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nVnXrlJ54eVU"
   },
   "source": [
    "# Introduction\n",
    "## What is Pandas?\n",
    "Pandas is one of the biggest and most popular libraries in Python for data science (among other things). \n",
    "\n",
    "- It allows you to load in data in the form of a **dataframe**, which is essentially a table, and then further lets you run fast calculations on the table's columns!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "cVgiQMnY1c4D"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 24 elements, new values have 25 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2666c102deb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m                              \u001b[1;34m\"hawaiian_pacificisl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiracial\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"international\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"unknown_race\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                              \u001b[1;34m\"all_african_american\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"all_native_american\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"all_hawaiian_pacificisl\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                              \"all_asian\", \"illinois\", \"non_illinois\", \"part_time\", \"full_time\"])\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mstu19\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stu19'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[0mskipfooter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipfooter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0mconvert_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_float\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         **kwds)\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[0;32m    454\u001b[0m                                  \u001b[0mskipfooter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipfooter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m                                  \u001b[0mconvert_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_float\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m                                  **kwds)\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_should_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m_parse_excel\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0masheetname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m                     \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0masheetname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msqueeze\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0masheetname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                     output[asheetname].columns = output[\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   4387\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4388\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4389\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4390\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4391\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m   3321\u001b[0m             raise ValueError(\n\u001b[0;32m   3322\u001b[0m                 \u001b[1;34m'Length mismatch: Expected axis has {old} elements, new '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3323\u001b[1;33m                 'values have {new} elements'.format(old=old_len, new=new_len))\n\u001b[0m\u001b[0;32m   3324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3325\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 24 elements, new values have 25 elements"
     ]
    }
   ],
   "source": [
    "#@title Please run this cell for setup!\n",
    "\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "if len(c.fetchall()) > 0:\n",
    "    c.execute(\"DROP TABLE IF EXISTS uber\")\n",
    "    c.execute(\"DROP TABLE IF EXISTS gpa\")\n",
    "\n",
    "uber_url = \"https://raw.githubusercontent.com/fivethirtyeight/uber-tlc-foil-response/master/Uber-Jan-Feb-FOIL.csv\"\n",
    "uber_data = pd.read_csv(uber_url, index_col=0)\n",
    "uber_data.to_sql('uber', conn)\n",
    "\n",
    "gpa_url = \"https://raw.githubusercontent.com/wadefagen/datasets/master/gpa/uiuc-gpa-dataset.csv\"\n",
    "gpa_data = pd.read_csv(gpa_url, index_col=0)\n",
    "gpa_data.to_sql('gpa', conn)\n",
    "\n",
    "stu19 = pd.read_excel('http://dmi.illinois.edu/stuenr/ethsexres/ethsexfa19.xls',\n",
    "                      header=4, sheet_name=\"summary\",\n",
    "                      names=[\"term\", \"code\", \"name\", \"st_level\", \"total\", \"men\", \"women\", \"unknown_gender\",\n",
    "                             \"caucasian\", \"asian_american\", \"african_american\", \"hispanic\", \"native_american\",\n",
    "                             \"hawaiian_pacificisl\", \"multiracial\", \"international\", \"unknown_race\",\n",
    "                             \"all_african_american\", \"all_native_american\", \"all_hawaiian_pacificisl\",\n",
    "                             \"all_asian\", \"illinois\", \"non_illinois\", \"part_time\", \"full_time\"])\n",
    "stu19.to_sql('stu19', conn)\n",
    "\n",
    "def run_query(query):\n",
    "    return pd.read_sql_query(query, conn)\n",
    "\n",
    "print(\"Setup Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2BlU99Y0ptHu"
   },
   "source": [
    "## Comparing SQL and Pandas\n",
    "Pandas Cheat Sheet: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n",
    "\n",
    "SQL Cheat Sheet: https://cdn.sqltutorial.org/wp-content/uploads/2016/04/SQL-cheat-sheet.pdf\n",
    "\n",
    "A workshop we conducted last semester on the same topic: https://drive.google.com/file/d/1NtRa_pueIMcpig-0-78xyVSW19OvSww0/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_6qYWkDZzuR"
   },
   "outputs": [],
   "source": [
    "stu19.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AdmOg0Pdrvf1"
   },
   "outputs": [],
   "source": [
    "# Pandas Version of SELECT\n",
    "\n",
    "stu19[\"name\"].head(5)\n",
    "\n",
    "# SQL equivalent:\n",
    "# SELECT name FROM stu19 LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ct6sAmTus7tU"
   },
   "outputs": [],
   "source": [
    "# Pandas Version of WHERE\n",
    "\n",
    "stu19[stu19[\"name\"] == 'Business '].head(5)\n",
    "\n",
    "# SQL equivalent:\n",
    "# SELECT * FROM stu19 WHERE name == \"Business \" LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ox-5wPw0-XH4"
   },
   "outputs": [],
   "source": [
    "# Pandas Version of LIKE\n",
    "\n",
    "stu19[stu19[\"name\"].str.contains(\"Bus\")].head(5)\n",
    "\n",
    "# SQL equivalent:\n",
    "# SELECT * FROM stu19 WHERE name LIKE \"%Bus%\" LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oXD1dP8Ts74O"
   },
   "outputs": [],
   "source": [
    "# Pandas Version of GROUP BY and aggregate functions\n",
    "\n",
    "# .sum can be replaced with .count, .mean, or others\n",
    "stu19.groupby([\"name\"]).sum().head(5)\n",
    "\n",
    "# SQL Equivalent:\n",
    "# SELECT SUM(term), ..., SUM(<last_numeric_col>) FROM stu19 GROUP BY name LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5LZRqjQ8ZPuJ"
   },
   "outputs": [],
   "source": [
    "new_df = stu19.set_index([\"name\", \"st_level\"])\n",
    "#new_df\n",
    "new_df.loc[[(\"Business \", \"Undergraduate \"),\n",
    "            (\"Education \", \"Graduate \")]]\n",
    "\n",
    "#new_df.loc[([\"Business \", \"Education \"], [\"Undergraduate \", \"Graduate \"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqCBhomOBcHq"
   },
   "outputs": [],
   "source": [
    "#Pandas Version of ORDER BY\n",
    "\n",
    "stu19.sort_values(by = [\"total\", \"women\"], ascending=False).head(5)\n",
    "\n",
    "# SQL Equivalent:\n",
    "# SELECT * FROM stu19 ORDER BY total DESC LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ALkrjLxuqJp1"
   },
   "source": [
    "## Some Basic Functions (not from SQL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4ZtTK5RzYHj"
   },
   "source": [
    "####`pd.DataFrame()`\n",
    "\n",
    "Sometimes you'll want to create your own DataFrame, there are **many** different ways you can do this with a whole variation of lists and tuples\n",
    "\n",
    "- You can check out [this page](https://www.geeksforgeeks.org/different-ways-to-create-pandas-dataframe/#:~:text=Pandas%20DataFrame%20can%20be%20created%20by%20passing%20lists%20of%20dictionaries,dictionary%20keys%20taken%20as%20columns.&text=%23%20Pandas%20DataFrame%20by%20lists%20of%20dicts.&text=%23%20Initialise%20data%20to%20lists.) for a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "unEHDjSAzXlP"
   },
   "outputs": [],
   "source": [
    "# a simple dataframe built from two lists\n",
    "data = {'SIG': ['pwny', 'glug', 'bot', 'aida', 'music', 'icpc', 'arch'], 'Coolest': ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']}\n",
    "df_sigs = pd.DataFrame(data)\n",
    "display(df_sigs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yozQmyUPzWDd"
   },
   "source": [
    "#### `.head(n)`\n",
    "\n",
    "- useful for when you just want to look at the first \"n\" rows in a dataframe \n",
    "- if n is not provided, the default is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCvpTG3HzTVV"
   },
   "outputs": [],
   "source": [
    "df_sigs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqFUcHcr01xq"
   },
   "source": [
    "####`.tail(n)`\n",
    "- does the same thing as .head(), just from the end\n",
    "- again, the default value for n is 5 (as you can see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BB-JhYi907Tq"
   },
   "outputs": [],
   "source": [
    "df_sigs.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m1e42OeP1TEl"
   },
   "source": [
    "####`.describe()`\n",
    "- returns a few possibly interesting statistics\n",
    "- the example below just shows you what you'll get when you run it on the array containing 1, 2, and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1jqzykqe1TRW"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'numeric': [1, 2, 3]})\n",
    "#display(df)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hFEwdW_Jrfxs"
   },
   "source": [
    "## Some Advanced Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5TFdArjy1yei"
   },
   "source": [
    "####`df_concatenated = pd.concat(_list_of_dataframes_)`\n",
    "- this one you can't call on any specific dataframe, rather you have to call it on pandas and set your output dataframe equal to it\n",
    "\n",
    "- as a side note, you can also use `append`, `merge`, and `join`\n",
    "- documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "syblIstg1yvC"
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
    "                   columns=['letter', 'number'])\n",
    "#       df1\n",
    "#   letter    number\n",
    "#     a         1\n",
    "#     b         2\n",
    "\n",
    "df2 = pd.DataFrame([['c', 3], ['d', 4]],\n",
    "                   columns=['letter', 'number'])\n",
    "\n",
    "#       df2\n",
    "#   letter    number\n",
    "#     c         3\n",
    "#     d         4\n",
    "\n",
    "df_both = pd.concat([df1, df2])\n",
    "print(\"after concat'ing df1 and df2\")\n",
    "display(df_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EtwZBM6H37q5"
   },
   "source": [
    "####`.apply(_function_)`\n",
    "- the `.apply()` function will take any other function as an argument and attempt to run it across the given dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrY4gLbI38YN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame([[\"Hello\", 9]] * 3, columns=['A', 'B'])\n",
    "\n",
    "#       df before running the apply function\n",
    "#    A       B\n",
    "#     4       9\n",
    "#     4       9\n",
    "#     4       9\n",
    "\n",
    "df\n",
    "\n",
    "#df.apply(np.sqrt)\n",
    "\n",
    "# pandas takes the square root of every possible row and cell in the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d7anAh3c5aBV"
   },
   "source": [
    "### You can also specify which columns you want the .apply() function to act on (and throw this into a new column!)\n",
    "\n",
    "- note that apply does not change the information that is already in the table, it gives you a column that you can pass into a new column creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_h0IdOlf5aTw"
   },
   "outputs": [],
   "source": [
    "df['B_sqrt'] = df['B'].apply(np.sqrt)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5izCQkh-38k0"
   },
   "source": [
    "####`.to_csv(_filepath_)`\n",
    "Last but certainly not least, how do you get your dataframe out?\n",
    "- you can provide really any .csv file for the filepath\n",
    "- if the csv file doesn't exist yet, pandas will make one\n",
    "- otherwise, pandas will overwrite the existing csv (so be careful!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vnBFNdPO383Z"
   },
   "outputs": [],
   "source": [
    "data = {'SIG': ['pwny', 'glug', 'bot', 'aida', 'music', 'icpc', 'arch'], 'Coolest': ['no', 'no', 'no', 'yes', 'no', 'no', 'no']}\n",
    "df_sigs = pd.DataFrame(data)\n",
    "display(df_sigs)\n",
    "\n",
    "df_sigs.to_csv(\"sig_coolness.csv\")\n",
    "\n",
    "# Congratulations! You now have a csv containing our original df_sigs dataframe we created at the start\n",
    "# Since we are working in Google colab, all files are saved in colab itself, so you'll need to click the folder icon on the left hand side of your colab window to see \"sig_coolness.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xyK1WqO2Qlc2"
   },
   "source": [
    "# Practice!\n",
    "Now here's a chance for you to practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xcHBImAvfGiX"
   },
   "source": [
    "### SQL to Pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zCt3EIL9mUcF"
   },
   "outputs": [],
   "source": [
    "# Problem 1: Find a class you've taken on campus before in the dataframe 'gpa_data'\n",
    "#   Note about pandas-specific syntax for AND, OR, NOT:\n",
    "#   https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing\n",
    "gpa_data['Subject'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A8VK5Bjfz-ya"
   },
   "outputs": [],
   "source": [
    "# Problem 2: Find the instructor with the highest number of A's given in the dataframe 'gpa_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQSi2vle0UHN"
   },
   "outputs": [],
   "source": [
    "# Problem 3: Find the department with the most number of instructors in the dataframe 'gpa_data'\n",
    "#   Then unique professors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FUoXCNn0eGf"
   },
   "outputs": [],
   "source": [
    "# Problem 4: Find a GPA for each class in the dataframe 'gpa_data'\n",
    "gpa_point_values = [4, 4, 3.67, 3.33, 3, 2.67, 2.33, 2, 1.67, 1.33, 1, 0.67, 0, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahvm4RZjxwx0"
   },
   "source": [
    "## Data Cleaning: Student Demographic Dataset\n",
    "Even before we begin our analysis, we need to be able to read in our dataset correctly! Download this dataset (305 kB): http://dmi.illinois.edu/stuenr/ethsexres/ethsexfa19.xls to your computer and open it using Excel; see if there would be any issues in reading this data into Python using Pandas (if you don't see any problems, try reading it in!)\n",
    "\n",
    "The function you should be using here is `pd.read_excel(\"filename or URL\")` (yes, we are directly reading from the URL for this example).\n",
    "\n",
    "Here is the documentation for `pandas.read_excel`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "O5ms6Y6E22TZ"
   },
   "outputs": [],
   "source": [
    "#@title Hint (double click me to open)\n",
    "# double click the right hand side to close\n",
    "\n",
    "# Hint 1: If you were to just load in the data, do you see many unnamed columns?\n",
    "# Now looking in the actual excel file, you can see that there are some\n",
    "# pieces of information at the top regarding the dataset (metadata). However,\n",
    "# Pandas does not like this in loading in our dataset because we ideally want\n",
    "# only a block of values.\n",
    "\n",
    "# Hint 2: There are some arguments that you can put into read_excel, mainly\n",
    "# header. This will let you specify the number of rows to skip/use as headers,\n",
    "# which allows us to skip the first few empty rows of metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YGHkcu1zKkW"
   },
   "outputs": [],
   "source": [
    "url = \"http://dmi.illinois.edu/stuenr/ethsexres/ethsexfa19.xls\"\n",
    "\n",
    "# load in data (you can use a variable that contains the url instead of\n",
    "# directly typing it in)\n",
    "\n",
    "# examine the first few rows to check that you've read in the right data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRo00b9O1Gva"
   },
   "outputs": [],
   "source": [
    "# Problem 5: Make a new dataframe combining the undergrad and graduate rows for each college (keeping the same columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66rlhntD3s4G"
   },
   "outputs": [],
   "source": [
    "# Problem 6: Using the dataframe from problem 5, make a new column showing the percentage of Hawaiian-Pacific Islanders in each college\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qp17hlk147l2"
   },
   "outputs": [],
   "source": [
    "# Problem 7: Explore this dataset (or any others) to your heart's content!\n",
    "#   Tell us if you find anything cool!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q077o1DRZ9Ni"
   },
   "source": [
    "# More!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vBD8jE4duHyt"
   },
   "source": [
    "## Plotting!\n",
    "The good thing about python libraries is a lot of the time they come built to have good interaction with other libraries. \n",
    "\n",
    "In this case, Pandas has built in integration with matplotlib, one of the most popular basic plotting libraries!\n",
    "\n",
    "Next week's workshop will be on cooler visualizations using other libraries (plot.ly specifically), so this is just an intro of what you can do with now cleaned data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "g-XACVOHsZt0"
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# This is our version of the cleaned dataset from the problems above\n",
    "stu19_plot = pd.read_excel('http://dmi.illinois.edu/stuenr/ethsexres/ethsexfa19.xls',\n",
    "                      header=4, sheet_name=\"summary\",\n",
    "                      names=[\"term\", \"code\", \"name\", \"st_level\", \"total\", \"men\", \"women\", \"unknown_gender\",\n",
    "                             \"caucasian\", \"asian_american\", \"african_american\", \"hispanic\", \"native_american\",\n",
    "                             \"hawaiian_pacificisl\", \"multiracial\", \"international\", \"unknown_race\",\n",
    "                             \"all_african_american\", \"all_native_american\", \"all_hawaiian_pacificisl\",\n",
    "                             \"all_asian\", \"illinois\", \"non_illinois\", \"part_time\", \"full_time\"])\n",
    "\n",
    "# Feel free to look up any of the functions you don't recognize here\n",
    "stu_genders = stu19_plot[['term', 'code', 'name', 'st_level', 'total', 'men', 'women', 'unknown_gender']]\n",
    "stu_genders.loc[:,'name'] = stu_genders.loc[:,'name'].str.strip()\n",
    "stu_genders.loc[:,'st_level'] = stu_genders.loc[:,'st_level'].str.strip()\n",
    "stu_genders_by_dept = stu_genders[['name', 'st_level', 'total', 'men', 'women', 'unknown_gender']]\n",
    "stu_genders_by_dept.set_index(keys=['name', 'st_level'], inplace=True)\n",
    "stu_genders_by_dept.sort_values(by='total', inplace=True)\n",
    "stu_genders_by_dept.loc[:,'agg_total'] = stu_genders_by_dept.groupby(by='name').transform(sum)['total']\n",
    "stu_genders_by_dept\n",
    "to_plot = stu_genders_by_dept.sort_values(by=['agg_total', 'st_level'])\n",
    "\n",
    "# .plot.bar() allows us to easily plot a bar graph!\n",
    "to_plot[['total', 'agg_total']].plot.bar(figsize=[10, 10],\n",
    "                                         title=\"Number of Students of Each Type in Each College vs. Total Number of Students in Each College\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8U2vlzEfRvR"
   },
   "source": [
    "## An anecdote from Michael:\n",
    "Pandas uses your computer's RAM to store the data it needs, primarily the dataframes you're working with. This means that if you happen to be working with a **_large_** amount of data, i.e. more than the amount of memory your computer has, Python will throw you a MemoryError and tell you it can't allocate the amount of space it needs on your computer.\n",
    "\n",
    "This happened to me over the summer at my internship when my dataframe got to be **212 Gb large** but my laptop only had 32 Gb.\n",
    "\n",
    "This probably won't happen to you unless your dataset is massive, but you can check out [_this website_](https://pythonspeed.com/articles/pandas-load-less-data/) if you want to see ways people have dealt with compression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyrxaRtzJZk-"
   },
   "source": [
    "### Next Week: Plotting with plot.ly!\n",
    "Quick preview of something we'll do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SRmuyCBrQAXZ"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "gpa = pd.read_csv(\"https://github.com/wadefagen/datasets/raw/master/gpa/uiuc-gpa-dataset.csv\")\n",
    "\n",
    "gpa['total_students'] = gpa['A+'] + gpa['A'] + gpa['A-'] + gpa['B'] + gpa['B+'] + gpa['B-'] + gpa['C+'] + gpa['C'] + gpa['C-'] + gpa['D+'] + gpa['D'] + gpa['D-'] + gpa['F']\n",
    "\n",
    "gpa['GPA'] = (gpa['A+'] * 4 + gpa['A'] * 4 + gpa['A-'] * 3.67 + gpa['B'] * 3 + gpa['B+'] * 3.33 + gpa['B-'] * 2.67 + gpa['C+'] * 2.33 + gpa['C'] * 2 + gpa['C-'] * 1.67 + gpa['D+'] * 1.33 + gpa['D'] + gpa['D-'] * 0.67) / gpa['total_students']\n",
    "gpa[\"4s given\"] = (gpa['A'] + gpa['A+']) / gpa['total_students']\n",
    "\n",
    "gpa_cs = gpa[gpa['Subject'] == 'CS']\n",
    "gpa_ece = gpa[gpa['Subject'] == 'ECE']\n",
    "gpa_abe = gpa[gpa['Subject'] == \"ABE\"]\n",
    "gpa_ae = gpa[gpa['Subject'] == \"AE\"]\n",
    "gpa_me = gpa[gpa['Subject'] == \"ME\"]\n",
    "gpa_bioe = gpa[gpa['Subject'] == \"BIOE\"]\n",
    "gpa_chbe = gpa[gpa['Subject'] == \"CHBE\"]\n",
    "gpa_npre = gpa[gpa['Subject'] == \"NPRE\"]\n",
    "gpa_mse = gpa[gpa['Subject'] == \"MSE\"]\n",
    "gpa_cee = gpa[gpa['Subject'] == \"CEE\"]\n",
    "gpa_ise = gpa[gpa['Subject'] == \"IE\"]\n",
    "\n",
    "gpa_engr = pd.concat([gpa_cs, gpa_ece, gpa_abe, gpa_ae, gpa_me, gpa_chbe, gpa_bioe, gpa_npre, gpa_mse, gpa_cee, gpa_ise])\n",
    "\n",
    "fig = px.scatter(gpa_engr, x = '4s given', y = 'GPA', size = gpa_engr['total_students'], color = gpa_engr['Subject'])\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_Intro_to_Data_Cleaning_(Worksheet).ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
